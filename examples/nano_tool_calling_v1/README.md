---
license: mit
task_categories:
- text-generation
language:
- en
tags:
- function-calling
- tool-calling
- synthetic
- openai
size_categories:
- n<1K
---

# Nano Tool Calling v1

A synthetic tool-calling dataset generated using [ToolsGen](https://github.com/atasoglu/toolsgen) with GPT-4.1-nano models.

## Dataset Details

- **Generated with**: ToolsGen v0.1.0
- **Source Tools**: [argilla-warehouse/python-seed-tools](https://huggingface.co/datasets/argilla-warehouse/python-seed-tools)
- **Total Samples**: 989
- **Language**: English
- **Format**: Single-turn conversations with tool calls

### Models Used

- **Problem Generator**: gpt-4.1-nano (temp=1.0)
- **Tool Caller**: gpt-4.1-nano (temp=0.0)
- **Judge**: gpt-4.1-mini (temp=0.0)

## Dataset Structure

Each record contains:

```json
{
  "id": "record_000000",
  "language": "english",
  "tools": [...],
  "messages": [
    {"role": "user", "content": "..."}
  ],
  "assistant_calls": [
    {
      "id": "call_...",
      "type": "function",
      "function": {
        "name": "function_name",
        "arguments": "{...}"
      }
    }
  ],
  "problem_metadata": {...},
  "judge": {
    "tool_relevance": 0.4,
    "argument_quality": 0.38,
    "clarity": 0.2,
    "score": 0.98,
    "verdict": "accept",
    "rationale": "...",
    "rubric_version": "0.1.0",
    "model": "gpt-4.1-mini",
    "temperature": 0.0
  },
  "quality_tags": [],
  "tools_metadata": {"num_tools": 2}
}
```

## Generation Details

### Configuration

- **Strategy**: Random tool sampling
- **Tools per sample**: 1-4 (k_min=1, k_max=4)
- **Parallel workers**: 16
- **Worker batch size**: 16
- **Max attempts**: 3
- **Seed**: 42

### Quality Control

All samples passed through an LLM-as-a-judge evaluation with a multi-dimensional rubric:

- **Tool Relevance** (40%): Are the selected tools appropriate?
- **Argument Quality** (38%): Are arguments valid and plausible?
- **Clarity** (20%): Is the response complete and clear?

Samples with `score >= 0.7` and `verdict == "accept"` are included.

## Usage

```python
from datasets import load_dataset

dataset = load_dataset("atasoglu/nano-tool-calling-v1")

# Access a sample
sample = dataset["train"][0]
print(sample["messages"])
print(sample["assistant_calls"])
```

## Source Tools

The dataset uses 38,420 Python function definitions from the [python-seed-tools](https://huggingface.co/datasets/argilla-warehouse/python-seed-tools) dataset, covering diverse programming tasks and domains.

## Limitations

- Single-turn conversations only
- English language only
- Synthetic data generated by LLMs (may contain artifacts)
- No actual tool execution or validation
- Judge scores are model-based assessments

## Citation

```bibtex
@software{toolsgen2025,
  title = {ToolsGen: Synthetic Tool-Calling Dataset Generator},
  author = {Ataşoğlu, Ahmet},
  year = {2025},
  url = {https://github.com/atasoglu/toolsgen}
}
```

## License

MIT License
